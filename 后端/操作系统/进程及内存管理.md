#### 进程控制块PCB
1. pcb会存储 `物理内存基址`，由于进程睡眠时会导致swap，会不停在磁盘与内存中 切入切出，导致基址会变。
2. 程序指令会在 `运行时重定位`: 根据 内存基址 + 指令偏移 找到真正的内存物理地址，cpu加载这个物理地址中的指令并执行。
   
#### 进程分段 及LDT段表
1. 程序编译后的指令加载到内存前，会被分段, 分成数据段、代码段..(分散加载，高效利用内存) 
    ```
    // 进程内存主要分为以下几个部分‌
    // 这些部分通过虚拟内存管理实现进程隔离，各部分通过不同增长方向避免空间冲突，由操作系统和编译共同维护‌
‌    1. 代码段 （Code Segment）‌：存放可执行的机器指令，通常只读，防止程序被意外修改‌
‌    2. 数据段 （Data Segment）‌：存储已初始化的全局变量和静态变量，程序加载时直接分配初始值‌
‌    3. BSS段 （Block Started by Symbol）‌：存储未初始化的全局变量和静态变量，进程启动时初始化为零或空‌
‌    4. 堆 （Heap）‌：动态内存分配区，通过malloc/new等函数分配，空间向高地址扩展，需要手动释放或由垃圾回收机制处理‌
‌    5. 栈 （Stack）‌：自动分配和释放的连续空间，存储局部变量、函数参数和返回地址，空间向低地址扩展‌
‌    6. 内存映射区 （Memory Mapping）‌：用于加载共享库、文件映射及匿名内存分配等‌。【mmap返回的指针属于进程的内存映射段，是独立于堆和栈的虚拟地址区域】
    
    ```
2. 段表里面有所有分段的[段标志位, 段基址]，cpu要执行某一个段里面的指令时，就会根据指令所属的段，在段表里面找到 `段基址`, 再加上指令的偏移量，定位跳转到物理内存某一个位置取指执行！
3. GDT表: 操作系统进程的段表
4. LDT表: 其他进程的段表, 也会放在PCB中。

#### 内存分区、分页
1. 操作系统会维护 内存空闲分区表、已分配分区表，表中每一项记录了起始地址与使用长度；程序分段找空闲内存时，会依据此表查询。(对虚拟内存的处理)
2. 解决内存碎片 > 物理内存会分页，针对每个 `程序段` 的内存请求，系统会一页一页的分配给这个段!
3. 页表[第几页, 页面尺寸4K, 读写权限]，cpu执行某个指令时，会根据MMU找到这个指令放在哪一页及页内偏移，从而定位到物理内存中指令的位置(用页号先定位到页框号，页框号才用来计算物理内存地址)。
4. 解决单级页表太大 > 多级页表[为页表建立多级目录] + 快表[寄存器, 存储最近使用的`页号`到物理`页框`的映射]，满足了`页号连续, 且占用内存小`的条件。

#### 段(面向用户侧)、页(面向硬件侧) 的重定位过程
1. 用户侧给出的逻辑地址: [cs:ip]表示[程序段，段的偏移量]
2. 首先根据 逻辑地址 在`段表`中查询段的基址，加上段的偏移量后，可以定位到指令在 `虚拟内存` 中的位置(虚拟地址)。
3. 再根据 `虚拟地址` 算出 `页号`、`页内偏移`，根据页号及偏移在`多级页表`中查询，得到页框地址(物理内存地址)
4. MMU硬件完成23步骤。

#### 用户程序载入内存
1. 用分区算法将 `用户程序段(代码段、数据段..)` 放入 虚拟内存的某一块区域中。设置段基址且会维护 `映射关系(建立段表)`。
2. 存放段的虚拟内存，会以页为单位存储在物理内存中。 设置页基址且会维护`映射关系(多级页表)`。
3. fork子进程后，会复制父进程的页表，页表中内容也拷贝，父子进程页表不同，但页表中指向的是相同物理地址。(会设置为只读，写会触发页中断)
4. 对子进程某页存储的内容进行修改的时候，触发页中断，才会真正分配新的物理内存页，然后将物理地址覆写到子进程页表。

#### 内存换入换出实现虚拟内存[swap分区管理]
1. 虚拟内存，虚拟地址空间，用户随意分配使用这4G内存地址空间。(用户侧不用关心物理内存的真实大小)
2. 运行时，才将程序从磁盘加载，根据映射关系，将虚拟地址 映射为 真实物理内存
#### 页面换入[请求调页]
1. MMU硬件根据逻辑地址算出页号后，查页表时，发现缺页，会产生 `缺页中断`，中断处理程序会从磁盘上读取这一页的内容，存储到物理内存分配页空间，然后设置映射关系。
#### 页面换出
1. 因为真实物理内存是有限的，并不能总是能获取新的页，所以需要选择一页换出到磁盘
2. 页面置换算法：FIFO先来先出，缺点：可能导致缺页异常多，不断的换入换出，从磁盘进行读写，慢
3. MIN算法：选择最远将使用的页换出，缺点：需要知道将来发生的事...
4. LRU算法：选择最近最少使用的页换出，特点：用过去的历史预测将来...【利用程序执行的局部性】
#### LRU实现
1. 每一页维护一个时间戳，选择具有最小时间戳的页进行换出 (每执行一条指令都要覆写这个时间戳值，要处理其溢出情况，放在操作系统中不合适)
2. 页码栈，新页落在栈顶，选择栈底的页进行淘汰..(指针要移动多次，慢)
3. 循环队列，每一页维护一个标记位，1表示最近访问过，指针循环访问队列中的每一页，扫描每一页的标记位，`遇1就置0，遇0就淘汰该页`。【最近没有使用 - 近似实现】
4. 方法3由于 `局部性原理`，缺页实际会很少，那么可能扫描指针转完整一圈后(第一圈扫描时都是1)，淘汰过程会退化成FIFO...
5. 在方法3基础上，再加上一个快指针，来清除R位(使1置0) 【快慢指针 - clock算法】

#### 给进程分配多少页框呢？
1. 分配很多时，页面很少换入，内存不能高效利用；
2. 进程很多时，导致每个进程分配的页框很少，那么缺页率增大，页面频繁从磁盘换入换出，进程会一直等待调页，cpu利用率降低... 【颠簸现象】



### PageCache
1. Page Cache：由内核管理的缓存区域，专用于缓存磁盘数据，是物理内存。
1. mmap：本质是在进程的虚拟地址空间中建立一段映射关系。返回一个指针操作文件，无需维护读写缓冲区。【适合需要随机访问或修改文件】
    ```
    // 返回的指针指向的是 虚拟内存地址
    // Page Cache的页面会被映射到进程的虚拟地址空间，但进程看到的是虚拟地址，实际数据仍存储在物理内存的Page Cache区域。
    1. 进程调用mmap，内核在虚拟地址空间中分配一段连续区域，并将其与文件关联（不立即加载数据）
    2. 进程首次访问映射区域的虚拟地址时，触发缺页异常，内核将文件对应部分从磁盘加载到物理内存（Page Cache）。

    mmap 按需建立映射，而非一次性加载整个文件。例如：
    映射一个 1GB 文件，mmap 仅在虚拟地址空间分配 1GB 的地址范围，但实际物理内存占用为 0；
    访问文件第 100MB 处时，内核加载对应的 4KB 页到 Page Cache，并更新页表映射。
    ```
2. sendFile：直接将内核空间（pageCache）的数据，转到socket buffer进行网络发送【仅支持文件→Socket传输】
    ```
    CPU 仅负责通知网卡进行DMA，不参与实际数据传输 （真正的零拷贝）
    ```
 

