### BitMap
1. 特征：数据集最大值决定了位数组的长度。
2. 原理：1bit 可表示 存在 或 不存在；2bit（可表示4种状态），3bit（可表示8种状态）。
3. 适合稀疏数据？ES中针对postingList的 `RBM压缩算法`。
   
#### 一、内存有限情况下，对大量密集型数据集实现排序、查找功能？
1. 前提：数据值不要重复，如果重复还需要一个count[]去记录重复的次数。
2. 原理：用每一个bit表示数值存在 或 不存在。
    ```
    // 换算成int[]，设N为数据集中最大值，1 int = 32 bit
    1. 数组的最大长度：(N / 32) + 1
    2. 将任意整数M放入数组中，数组下标：M / 32；占用下标处int的哪个位：M % 32
    3. 例如讲数字5放入数组，数组下标：5 / 32 = 0；占用下标处int的哪个位：5 % 32 = 5；即赋值：b[0] = b[0] | (1 << 5)
    ```
3. 排序就展开int[]的bit序列，计算并输出bit值为1的 `位下标`。
4. 判断某数值是否存在就用：`b[0] & (1<<5) == 1`。

#### 二、内存有限情况下，对大量密集型数据集实现去重功能？
1. 问题：20亿个整数中，找出不重复的整数的个数（值也可以输出），内存不足以容纳这20亿个整数。
2. 原理：利用 2bits 对一个关键字的状态进行存储，不存在记为00，存在一次01，存在两次及以上用11。
3. 位图解决方法：
    ```
    // 同样可以采用int[]
    1. 把这20亿个数字放进去，同样先计算数组下标和对应的位。
    2. 放入过程中，如果对应的状态位为00，则将其变为01，表示存在一次；如果对应的状态位为01，则将其变为11；表示已出现多次；如果为11，则对应的状态位保持不变，仍表示出现多次。
    3. 遍历int[]中的所有bit序列，统计状态位为01的个数，就得到了不重复的数字个数，时间复杂度为O(n)。
    4. 2个bit上的数值，可以通过int[]下标 与 位的下标，反向计算出来。
    ```
4. 分治法：
    ```
    // Map-Reduce思想
    1. 利用Hash的方法，把这2.5亿个数划分到更小的文件中，以确保每个文件的大小超过可用的内存大小。
    2. 接着针对每个小文件来说，所有的数据可以一次性被加载到内存中，因此可以使用字典或者set来找到每个小文件中不重复的数。
    3. 当处理完所有的文件后，将所有处理结果汇总，再去重一次，就可以找出这2.5亿个整数中所有的不重复的数。
    ```

### 布隆过滤器
1. 是一个很长的二进制向量或BitMap，和k个hash函数实现的。k个hash函数会对输入参数进行计算出一个值v，然后将这个v作为下标，下标为v的bit存1。
2. 用于判断某个输入参数 `一定不存在` 或者 `可能存在`。[hash冲突, 待查询的输入，经过hash后的v，可能v下标处已经被标记为1]。

#### 一、Nosql数据库利用来优化查询性能
1. 在内存中，构建并动态调整bloom filter，来优化整个系统的查询性能。在内存中就能拦截一部分key，判断出一定不存在的key就不再请求磁盘。
2. 布隆过滤器 + 建立稀疏索引, 来优化查询操作；代价小于以B/B+树为基本数据结构的传统RDB存储引擎[多次IO导致多次磁盘寻道]。


### 一致性哈希算法
1. 目的：解决了普通余数Hash算法伸缩性差的问题，可以保证在上线、下线服务器的情况下尽量有多的请求命中原来路由到的服务器。
2. 具体使用方法如下：
    ```
    1、先构造一个长度为 2^32 的整数环（这个环被称为一致性Hash环）, [0, 2^32 -1]。
    2、服务器节点(真实及虚拟)的名称进行hash后，会落在该环上。
    3、对要存储的数据Key，进行hash后也落在该环上。
    4、在Hash环上顺时针查找距离这个Key值的Hash值最近的服务器节点，那么这个key就存储在这个服务器上。
    ```
3. 注意点：
   - 不能用String的hashCode()，分配不均匀；用CRC16_HASH、CRC32_HASH、FNV1_32_HASH、KETAMA_HASH等。
   - 采用真实节点对应多个虚拟节点，来解决(伸缩时)负载分布不均匀问题。
   - 节点数越少，越容易出现节点在哈希环上的分布不均匀，导致各节点映射的对象数量严重不均衡(数据倾斜)；相反，节点数越多越密集，数据在哈希环上的分布就越均匀。但实际部署的物理节点有限，我们可以用有限的物理节点，虚拟出足够多的虚拟节点(Virtual Node)，最终达到数据在哈希环上均匀分布的效果。