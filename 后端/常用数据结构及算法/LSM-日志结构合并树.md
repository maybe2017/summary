### 一、背景
1. NoSQL数据库，如RocksDB、LevelDB、HBase以及Prometheus等，底层的存储引擎都是基于LSM树。
2. 相比于B/B+树、倒排索引，LSMTree采用了 `极致的磁盘顺序写` 方案，满足了极致的写吞吐量。

### 二、定义简述
1. LSM树是一个横跨内存和磁盘的，包含多颗子树的一个森林。
2. LSM树分为Level-0，Level-1，Level-2 ... Level-N 多颗子树，其中只有 `Level-0` 在内存中，其余 `Level[1~N]` 在磁盘中。
3. 内存中的Level-0子树一般采用排序树[红黑树、AVL树]、跳表或者TreeMap等这类有序的数据结构，方便后续 `顺序写磁盘`。
    ```
    1. 有序至关重要，正是因为有序，读写才快。
    2. 维护内存中Level-0子树的有序，也保证了在写入磁盘Level-1子树 `新Block` 时，是有序写入的。
    ```
4. 磁盘中的 `Level[1~N]` 子树，本质是数据排好序后顺序写到 `磁盘上的一个个文件`，只是叫做树而已。
5. 每一层的子树都有一个阈值大小，达到阈值后会进行合并，合并结果写入下一层。
6. 只有内存中数据允许原地更新，磁盘上数据的变更只允许追加写，不做原地更新。

### 三、增删改查

#### 插入操作
插入数据按照key的大小，往 `内存中的Level-0排序树` 依次放即可，时间复杂度为树高log(n)，而且是在内存中，速度极快！

![alt text](image_url "optional title")

#### 删除操作
1. 删除并不会直接立刻删除数据，而是通过一种叫 `墓碑标记` 的特殊数据 `先标识` 待删除数据。
2. 删除操作分为：待删除数据在内存中、待删除数据在磁盘中 和 该数据根本不存在 三种情况。



https://zhuanlan.zhihu.com/p/415799237
### 读放大与写放大 https://cloud.tencent.com/developer/article/1352666
1. LSM-Tree 能将离散的随机写请求都转换成批量的顺序写请求（WAL + Compaction），以此提高写性能。
    - 读放大：读操作需要从新到旧一层一层查找，直到找到想要的数据。这个过程可能需要多次I/O。特别是`range query`的情况，影响很明显。
    - 空间放大：因为所有的写入都是`append-only顺序写`的，不是 `原地更新`，所以过期数据不会马上被清理掉。
    - 写放大：实际写入 HDD/SSD 的数据大小和程序要求写入数据大小之比
    ```
    // HDD 作为存储，compaction 带来的写放大问题并没有非常明显
    1. HDD 顺序读写性能远远优于随机读写性能，足以抵消写放大带来的开销。
    2. HDD 的写入量基本不影响其使用寿命。

    // SSD 作为存储，compaction 带来的写放大问题显得越来越严重
    3. SSD 顺序读写性能比随机读写性能好一些，但是差距并没有 HDD 那么大。所以，顺序写相比随机写带来的好处，能不能抵消写放大带来的开销，这是个问题。
    4. SSD 的使用寿命和其写入量有关，写放大太严重会大大缩短 SSD 的使用寿命。因为 SSD 不支持覆盖写，必须先擦除（erase）再写入。而每个 SSD block（block 是 SSD 擦除操作的基本单位） 的平均擦除次数是有限的。

    // 写放大、读放大、空间放大，三者就像 CAP 定理一样，需要做好权衡和取舍
    ```
2. 读放大由为了检索数据而需要读取多个表所引起
3. 写放大由compaction过程中不断进行的重写所引起
4. 读放大指的是在进行范围查询时，LSM-Tree需要进行多次的合并操作，以获取所需的数据。由于上层的新数据可能会覆盖下层的旧数据，并且层与层之间存在交集，因此可能需要进行多次的合并操作才能获取一段数据。这种多次合并操作会导致读放大，即需要读取的数据量比实际数据量更大。
5. 写放大指的是在进行写入操作时，LSM-Tree需要进行多次的磁盘写入操作。每次写入操作都需要将数据写入日志（log）和刷新脏页（flush dirty page）两个步骤。即使只修改了一个字节的数据，也需要将整个页写入磁盘。这种多次的磁盘写入操作会导致写放大，即实际写入的数据量比修改的数据量更大。