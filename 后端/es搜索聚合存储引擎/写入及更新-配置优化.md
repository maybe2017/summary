
### 几个基础
1. WAL：write-ahead-log，即先写日志，再写入真实的数据。【mysql的binlog】【一般来说该类日志文件都是顺序append，性能较高】
2. fsync系统调用：将osCache中的数据强制刷到磁盘。【调用间隙间，可能出现系统断电导致osCache数据丢失】
3. buffer：一块缓存空间，程序上的设计使用；需要与osCache区分开。【mysql中的 Buffer Pool】
4. ES中的一个shard就是一个lucene索引，一个lucene索引被分解成多个段。


### 写入时的层级顺序
1. buffer：doc及index数据会先写入buffer中，同时追加写入Translog，且实时 `fsync落盘`，然后返回客户端成功。【此时不可被搜索，但用_id可以搜索】
    ```
    // 与数据库不同点
    数据库是先写CommitLog，然后再写内存，而Elasticsearch是先写内存，然后才写TransLog

    // 原因
    Lucene的内存写入会有很复杂的逻辑，很容易失败，比如分词，字段长度超过限制等，比较重，为了避免TransLog中有大量无效记录，减少recover的复杂度和提高速度，所以先写buffer

    // GetById搜索
    这种查询可以直接从TransLog中查询，这时候就成了RT（Real Time）实时系统
    ```
2. osCache：操作系统层级的缓存，buffer层级的数据默认每隔一秒，将buffer中的数据生成新的Segment，并写入osCache，此时Segment被置为open状态。【此时可被搜索-近实时搜索系统】
3. disk：osCache中的众多Segment文件，会被 `flush` 操作强制刷到磁盘；该部分对应的历史TransLog会被清空掉。【默认30分钟，或者Translog日志文件达到长度阈值】。


### 写入原理

#### 写入过程
1. 新写入的文档首先被写入内存缓冲区（In-memory Buffer），每隔一秒转换成新的Segment，并清空Memory Buffer；此时Segment为 Closed 状态，不可被搜索。【Refresh】
2. 写入原理图示例：
    ```mermaid
    sequenceDiagram
        Client->>Memory Buffer: 写入文档
        Memory Buffer->>OS Cache: 默认每隔1s进行 Refresh 生成 Segment（Open 状态）
        OS Cache->>Disk: Flush 异步刷盘
    ```
3. Flush落盘操作（默认30分钟或 Translog 文件写满触发）【风险，30分钟太长，可能节点宕机，此时就需要TransLog进行故障恢复，以保证数据一致性】
    ```
    1. 调用 fsync 将 OS Cache 中的 Segment 持久化到磁盘。
    2. 清空 Translog（事务日志）

    ```

#### 段合并 Segment-Merge
1. 由于自动Refresh流程每1s就会产生一个Segment，这样短时间内Segment会暴增，消耗句柄等资源，且每次请求都会轮流查每个Segment，使搜索变慢。
2. 所以ES在后台会执行 段合并 操作来解决这个问题，合并成新的大的段之后写入osCache，且被置为open状态，旧 Segment 被标记为 Deleted，随后物理删除。
3. 在JVM中执行，频繁执行会消耗大量资源；优化方案，考虑扩大内存buffer，或使Refresh间隔大一点，减少单位时间内Segment的生成，从而降低段合并的频率。【优化反向】


#### TransLog【其落盘时间远远小于Segment落盘时间】
1. 每次写入请求都会 立即追加记录（类似 MySQL 的 WAL 日志），确保即使 Segment 未刷盘，数据也不会丢失。【宕机情况】
    ```
    实时持久化：在Segment未刷盘前，Translog 记录所有写入操作，确保数据可恢复。【默认断电情况下最多丢近5s的数据】
    故障恢复：节点崩溃后，通过重放 Translog 恢复未持久化的数据。
    ```
2. 默认每隔5s刷盘一次，也可以每次写入请求后强制fsync落盘。
3. Translog 是顺序写入：数据严格按照先后顺序追加到文件末尾（Append-Only），不修改已有内容。【最大化写入吞吐量】
    ```
    顺序写入: 连续磁道访问
    随机写入: 慢（磁头频繁移动）
    ```

#### CommitPoint
1. 当 Segment 成功 Flush 到磁盘后，生成一个 translog.ckp 文件，标记哪些 Translog 可删除。
2. 后台合并（Merge）时会清理已持久化的 Translog 记录。



### Update更新
1. 早期版本ES是采用乐观锁即版本号_version来控制文档的并发更新
    ```
    悲观锁：认为每次更新的时候，都会有其他线程也去更新，所以加上了锁，再去访问。  - 适合竞争很激烈的场景。
    乐观锁：认为冲突的概率较小，采用版本号来解决冲突问题。  - 适合竞争很少的场景，如果竞争很多还采用CAS，那么时间就一直浪费在不断比对重试上。                    

    ES文档级别的版本号：_version，即当前文档每被更新就加一。
    ES索引级别的版本号：_seq_no，索引下任意文档被更新，该值就加一。
    主分片版本号：primary_term，每当主分片宕机，重新选举后，会有副本分片提升为新主分片，那么该值会加一。
    ```

2. 更新原理：先给doc打上删除flag，再新增


### 查询 - Search类请求 与 Get类请求
1. Get请求：通过ID查询特定Doc；一阶段查询的时候就返回完整Doc【query_and_fetch】
    ```
    // 这种查询是实时的，满足NoSQL场景下的实时性要求
    对于Get类请求，查询的时候是先查询内存中的TransLog，如果找到就立即返回，如果没找到再查询磁盘上的TransLog，如果还没有则再去查询磁盘上的Segment。
    这种查询顺序可以保证查询到的Doc是最新版本的Doc。
    ```
2. Search请求：通过Query查询匹配Doc；第一阶段查询到匹配的DocID，第二阶段再查询DocID对应的完整文档【query_then_fetch】
    ```
    // 近实时的
    对于Search类请求，查询的时候是一起查询内存和磁盘上的Segment，最后将结果合并后返回。

    因为数据会先写进buffer，1s后再整理为Segment对象Refresh到OsCache

    ```

### 参数调优
#### refresh_interval
1. Refresh操作默认每秒执行一次， 将内存缓存区的数据写入到文件缓存区的一个新的Segment中，同时清空内存缓存区。【索引变成了可被检索】
2. 默认情况下，`refresh`操作设置为每秒执行一次，可以通过参数 `index.refresh_interval` 来修改这个刷新间隔。
3. refresh的开销比较大，因此在【批量构建索引】时可以把refresh间隔设置成 -1 来 `临时关闭` refresh，等到索引都提交完成之后再 `重新打开` refresh。
    ```
    // 可通过如下接口修改这个参数
    curl -XPUT 'localhost:9200/test/_settings' -d '{"index" : {"refresh_interval" : "-1"}}'

    ```


    ```json
    PUT /my_index/_settings
    {
        "index.translog.durability": "async", // 默认是同步fsync
        "index.translog.sync_interval": "120s", //  默认是5s，最多丢失最近 5s 数据（可通过副本分片降低风险）
        "index.translog.flush_threshold_size": "1024mb", // 默认是512M
        "refresh_interval": "120s" // 默认是1s
    }


    ```








    
