## 索引是什么？
帮助快速检索，以数据结构为载体，文件形式落地。

## 一、常用字段类型
1. 字符串string
    ```
    1. keyword, 需要精确值查询, 支持过滤、排序、聚合。如id字段。
    2. text, 但一个字段需要被全文搜索时, 生成倒排索引前, 字段值会被分词为一个个的词项term。该类型不用于排序, 也很少用于聚合, 所以默认禁用了正排索引的生成！[代价大] 
    3. 如字段既需要全文搜索, 又需要聚合与排序, 那么text与keyword都需要在该字段中存在。
    ```
2. date时间类型

## 二、性能-内存
1. es大量基于OS cache进行缓存与提升性能, 不建议使用Jvm内存进行缓存, 可能导致gc及omm问题。
2. 官方建议64G内存服务器, 16G给Jvm, 留给OS cache更大的内存, 来提升doc_value和倒排索引的缓存及查询效率。

## 三、正排索引【doc_values】
1. 目的: 为了term项的 `高效聚合`
2. 默认支持生成正排索引的字段类型：keyword、数值、日期、IP、地址位置等；但一些type如`text`默认为不支持

3. 不分词的field会在index-time时生成正排索引，聚合的时候能直接使用。而分词的field或创建索引时没有生成正排索引的字段，这些字段需要进行聚合时，就需要将fielddata开启，相当于在内存中临时生成索引。
4. 对默认不支持生成正排索引的字段类型，如text类型, 需要生成正排索引时, 采用 `fileddata:true`, 但是这会使用Jvm内存。
    ```
    "mapping":{
        "tags": {
            "type" : "text",
            // 关闭生成倒排索引
            "index" : "false",
            // 关闭生成正排索引；默认开启值为true
            "doc_values" : false 
        }
    }
    ```

## 四、倒排索引
1. 目的: 为了term项的 `高效查询`
2. 组成: term index，term dictionary，postingList
    ```
    // term dictionary
    词项字典，分词得出，无重复
    
    // term index
    词项索引

    // postingList
    倒排表，每一个term项对应一个postingList, postingList中装了 `包含这个term项的所有docId`[已排序]
    ```

## 五、高效的压缩算法、及快速的编码解码速度

### 压缩`倒排表PostingList`中docIds的算法
- 倒排表PostingList中，存储的是文档的id，认为是int类型的一个从小到大排序的数组？
- 考虑如何压缩？让大数变为小数，那么保存小数占用的bit数就少
- 稠密数据，那么其deltaList中的数值都会很小，就达到了用较少的bit存储其值的效果
- 稀疏数据，其deltaList中的数值可能很大，达不到压缩的效果，此时则考虑除法，让除以某个固定的数，得到商和余数，那么用(商，余数)代替表示原来的数，商和余数如果是很小的数字，那么也达到了压缩效果。
  

#### FOR(Frame of Reference - 通过增量编码的方式对文档ID列表进行压缩，从而提高存储效率和查询速度)
1. 压缩数据需要的特征: 稠密数据集, 已排序。因为稠密型的数据集, 其差值必然也很小, 可以用更少的bit存储, 从而取代每一个数都用int存储，达到压缩效果。
2. 增量编码‌：从第二个文档ID开始，每个文档ID存储与前一个ID的差值，即delta值。例如，对于文档ID列表[73, 300, 302, 332, 343, 372]，增量编码后的结果为[73, 227, 2, 30, 11, 29]。
3. ‌分组压缩‌：将差值再次进行分组并进行位压缩。Lucene通常将文档ID列表分成256个区块，每个区块使用不同的编码方式。例如，每个区块中最大的数字决定该区块所有数字的存储位数，从而实现对整个列表的高效压缩‌。
    ```
    // 再次分组压缩 [每个组的信息都会用一个字节去保存记为flag - 用于解压缩还原]
    [73, 227, 2, 30, 11, 29] => [73, 227], [2, 30, 11, 29]
    那么第一个数组中最大值为227，2的8次方=256，即数组中每个数字至多用8个bit存储即可，共计2*8bit = 2Byte
    同理第二个数组中最大值为30，2的5次方=32，即数组中每个数字至多用5个bit存储即可，共计4*5bit = 3Byte
    ```
4. 实现核心: 计算相邻数据间的`差值`, 将 `差值list` 按数值大小适当分组[数值相近的存放为一组]。
  
#### RBM(RoaringBitMap)
1. 压缩数据需要的特征: 稀疏数据集, 已排序。
2. 考虑到docId为int类型, 最大为2^31, [约定除数为2^16], 那么 `商和余数` 都会小于2^16, 即65535。且因为被除数PostingList是有序不重复的，那么得出的商也是有序的，余数也是有序不重复的。
3. 考虑每一个商值可采用short类型进行存储，那么整个PostingList数组计算出来的商集，就可使用short[]存储
4. 余数如何存储呢？商和余数如何关联起来，去表示PostingList中的数呢？
    ```
    // 商和余数如何关联？假如（0,1000）（0,62101）（2,321）（2,185）是PostingList计算出的商和余数
    short[0]即存商值0，拟作为一个key；而value呢？则用一个Container容器去存储所有商值为0的余数集

    // 而Container容器，有下面三种类型
    1. 当需要存储的docId个数 <= 4096时, 采用 `ArrayContainer`, 其中用short类型存储每一个余数
    2. 当需要存储的docId个数 > 4096时, 采用 `BitMapContainer`
    3. 如果余数集恰巧是连续的, 可采用 `RunContainer`, 如（1,2,3,4,5,6,7,8,9,10）即可压缩为（1,10），表示有10个连续的1。这种情况很少。

    // ArrayContainer
    其占用空间大小与存储数字个数呈线性正比的，因为每个商值对应的余数集元素个数至多有65535个，所以该容器也最多存65535个数，65535 * 2字节 / 1024 = 128kb，即容器随存储元素递增，至多占用[0kb~128kb]。
    // BitMapContainer
    其占用空间大小与存储数字个数是无关的，因为BitMap的特性，65535个bit可以表达0~65535间任意数是否存在，那么其也至多可用于存储65535个数（N<65536），65536 bit / 8 / 1024 = 8kb，所以无论存储多少个数（0~65536），该容器都占用8kb。
    // 8kb是一个临界值
    基于以上两点，可推断出，每个商对应的余数集个数，决定了余数集用什么类型的Container进行存储，从而达到压缩效果。
    ```

### FST有限状态转换器【键值映射 + 前缀搜索 + 压缩存储】【使 Elasticsearch 能在 低内存消耗 下高效支持 全文检索、前缀搜索和拼写纠正】
1. Lucene/Elasticsearch 用 FST 存储 字典项（Terms dictionary）。
    ```
    1. 类似字典树（Trie），但通过共享后缀/前缀优化存储 - 支持前缀搜索
    2. 共享公共前缀和后缀，大幅减少内存占用（比哈希表、纯Trie更节省空间）；示例："cat" 和 "cats" 共享前缀 "cat"; "quickly" 和 "slowly" 共享前缀 "ly"
    ```
2. 搜索词自动补全。
    ```
    // 使用 FST 实现高性能的 前缀匹配搜索（如搜索框输入 "app" 提示 "apple"）
    1. FST 存储补全词项及其权重（如 {"apple": 10, "app": 5}）。
    2. 查询时：遍历 FST 找到所有匹配前缀的词项并按权重排序。
    ```    
3. 它类似是一个Map吗？key和value分别是什么？ 
    ```
    FST对外并不直接表现为一个传统的 Map 结构，但其逻辑功能可以类比为一个 压缩的、支持前缀查询的键值映射【key存的是term，value存储的是对应PostingList的指针】

    // FST 中 Value 的具体内容
    1. Posting List 的偏移量（File Offset）：指向磁盘上倒排列表的位置（Lucene 的 .doc 文件）
    2. 统计信息：词频（Term Frequency）、文档频率（Doc Frequency）等。
    3. Block 编码信息：存储 Block 的起始位置。
    ```   