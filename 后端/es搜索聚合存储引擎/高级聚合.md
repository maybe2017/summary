
### 三角选择原则
1. 大数据、实时性、精准度；三者只能满足其二。
2. Hadoop（大数据、精准度）
3. Mysql（实时性、精准度）
4. ES（大数据、实时性）

### 聚合
- 需要先在多个分片中计算结果，再综合多个分片的结果，重新计算（ps场景：如深度排序分页）
- 

#### 易并行算法
1. Min、Max、Avg、Sum等指标函数，通常只需要在多个分片中计算一个值进行汇总计算，不会消耗很多内存资源。

#### 不易并行算法
1. Cardinality函数：由于无法在不同分片中保证数据是否重合，需要消耗很多内存，用于汇总各分片中的聚合数据，再进行基数聚合，尤其是高基数聚合。
2. 高基数：不重复值的个数很大；如订单表中的手机号码。 - 聚合性能差
3. 低基数：重复值的个数很大；如订单表中的所属省份等。 - 聚合性能好


#### Cardinality函数聚合

1. Cardinality函数内部会默认使用`HyperLogLog++ 算法`，主要用于ES高效计算 唯一值（Distinct Values）的数量。在做Cardinality函数运算的时候，ES会动态的为每一个field vaule计算hash，来提升聚合性能。
    
    ```
    // 优化方案：安装插件mapper-murmur3【提升Cardinality函数的聚合性能 - 仅建议在低基字段使用】
    原理：预先为field vaule计算hash，做Cardinality函数运算的时候，就可以直接使用。

    适合的场景：需要快速统计 大规模数据的唯一值数量（如不同用户数UV、独立 IP 访问量、去重后的商品 ID 数量）。
    不适合的场景：
        需要财务计算等精确结果；
        唯一值数量极少（如 < 100），此时直接使用 terms 聚合更高效。

    如果需要精确计数：
        对小数据集使用 terms 聚合 + size 参数
        对大数据集使用 离线计算（如 Spark）    
    ```
2. 为尽量满足：实时性 + 海量数据，精准度丢失了1% - 6%
   
    ```
    // 优化精确度方案
    可以在使用Cardinality函数时，内部用参数precision_threshold来控制用内存换取精度，取值范围为[3000,4w]，值越大，换取的精度越高。
    precision_threshold = 1000时，内存约消耗 8kb
    precision_threshold = 4w时，内存约消耗 320kb，即每一个查询会额外消耗320kb的内存。
    ```    
3. 示例用法：统计订单表中每天的唯一用户数
    ```json
    {
        "aggs": {
            "daily_unique_users": {
                "date_histogram": {
                    "field": "order_date",
                    "calendar_interval": "day"
                },
                "aggs": {
                    "uv": {
                        "cardinality": {
                            "field": "user_id",
                            "precision_threshold": 1000  // 提高精度（内存占用增加）
                        }
                    }
                }
            }
        }
    }
    ```    